{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d18f2ae-6f2f-4e02-8a8f-7705dc58a0a0",
   "metadata": {},
   "source": [
    "# The ML Pipeline for a Model to Predict Length of Hospital Delivery Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5518be3a-a2d7-4257-9c38-6703d13f65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from math import ceil\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5a1ca-7848-424a-9496-812f219a4f2b",
   "metadata": {},
   "source": [
    "# Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e4b4ad-3113-4607-9dc8-7d8219e08ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying data types for the columns to maintain formatting from original data\n",
    "data_types = {\n",
    "    'hospital_service_area': object, \n",
    "    'hospital_county': object,\n",
    "    'operating_certificate_number': object, \n",
    "    'permanent_facility_id': object,\n",
    "    'facility_name': object, \n",
    "    'age_group': object, \n",
    "    'zip_code_3_digits': object, \n",
    "    'gender': object, \n",
    "    'race': object,\n",
    "    'ethnicity': object, \n",
    "    'payment_typology_1': object, \n",
    "    'payment_typology_2': object,\n",
    "    'payment_typology_3': object, \n",
    "    'length_of_stay': int\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92c8a7f-f003-49d7-86cb-da3aa7fe66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits = pd.read_csv('../data/planned_deliveries.csv', dtype=data_types)\n",
    "all_visits = all_visits.loc[:, all_visits.columns != 'Unnamed: 0']\n",
    "y = all_visits['length_of_stay']\n",
    "X = all_visits.loc[:, all_visits.columns != 'length_of_stay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07438df2-eb49-4f80-83e3-fc42faf02db8",
   "metadata": {},
   "source": [
    "# Compute Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83961471-f678-48f1-af2e-da41e76fff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of stay: 2.3057860029780897\n",
      "Median length of stay: 2.0\n"
     ]
    }
   ],
   "source": [
    "mean_length_of_stay = np.mean(y)\n",
    "median_length_of_stay = np.median(y)\n",
    "print('Mean length of stay:', mean_length_of_stay)\n",
    "print('Median length of stay:', median_length_of_stay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d265b4-d6ff-4c8f-aa80-ce64361d677f",
   "metadata": {},
   "source": [
    "#### R^2 [dimensionless]  \n",
    "**Pretty sure this is unnecessary to do though since by definition R^2 should = 0 for the expected (average) guess of y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af85367-e63d-4c2f-ab54-1f58d6b5e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mean = pd.Series([mean_length_of_stay]*len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197c0d07-b106-436e-8926-284a39e39b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 [dimensionless]: 0.0\n"
     ]
    }
   ],
   "source": [
    "baseline_r2 = r2_score(y, y_pred_mean)\n",
    "print('Baseline R^2 [dimensionless]:', baseline_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67f90d-05e3-4fee-8248-399ab2d3e1a1",
   "metadata": {},
   "source": [
    "# Split, Train, and Cross Validate - R^2 Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060340e6-636f-4303-b339-11d38a3f3d63",
   "metadata": {},
   "source": [
    "### Set up functions for automated pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b22cb-7295-4196-88ed-683cf96792c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_continuous_split(X:pd.DataFrame, y:pd.Series, train_size:float, val_size:float, test_size:float, random_state:int):\n",
    "    '''\n",
    "    Performs a stratified split of inputted data (with respect to y) into a training set, validation set, and test set to specified percentages \n",
    "    of the data using verstack's scsplit and performs basic error checking.\n",
    "\n",
    "    Parameters:\n",
    "    - X: a 2D pandas DataFrame, the feature matrix\n",
    "    - y: a 1D pandas Series, the target variable matrix matching X\n",
    "    - train_size: a float between 0 and 1, the percentage of X which should be training data\n",
    "    - val_size: a float between 0 and 1, the percentage of X which should be reserved for validation\n",
    "    - test_size: a float between 0 and 1, the percentage of X which should be reserved for final testing\n",
    "    - random_state: an int, the random state to split with\n",
    "    Note: The sum of train_size + val_size + test_size must be 1.0 (100% of X).\n",
    "\n",
    "    Returns:\n",
    "    - (X_train) a 2D pandas DataFrame, the feature matrix of training data\n",
    "    - (y_train) a 1D pandas Series, the target variable matrix for training data\n",
    "    - (X_val) a 2D pandas DataFrame, the feature matrix of validation data\n",
    "    - (y_val) a 1D pandas Series, the target variable matrix for validation data\n",
    "    - (X_test) a 2D pandas DataFrame, the feature matrix of testing data\n",
    "    - (y_test) a 1D pandas Series, the target variable matrix for testing data\n",
    "\n",
    "    Raises:\n",
    "    - ValueError for invalid input\n",
    "    '''\n",
    "    from verstack.stratified_continuous_split import scsplit\n",
    "    \n",
    "    if ((train_size + val_size + test_size) != 1):\n",
    "        raise ValueError('Your train_size + val_size + test_size must add up to 1 (100%)!')\n",
    "    if (not isinstance(random_state, int)):\n",
    "        raise ValueError('Your random_state must be an int!')\n",
    "\n",
    "    X_train, X_other, y_train, y_other = scsplit(X, y, stratify=y, test_size=(1-train_size), random_state=random_state)\n",
    "    \n",
    "    X_len = X.shape[0]\n",
    "    test_percent_of_other = (test_size * X_len)/(X_len - (train_size * X_len))\n",
    "    X_other = X_other.reset_index(drop=True)\n",
    "    y_other = y_other.reset_index(drop=True)\n",
    "    \n",
    "    X_val, X_test, y_val, y_test = scsplit(X_other, y_other, stratify=y_other, test_size=test_percent_of_other, random_state=random_state)\n",
    "\n",
    "    # basic error checking to check that split returned train, val, and test of expected sizes\n",
    "    train_count_low = (int)(train_size * X_len)\n",
    "    train_count_high = ceil(train_size * X_len)\n",
    "    val_count_low = (int)(val_size * X_len)\n",
    "    val_count_high = ceil(val_size * X_len)\n",
    "    test_count_low = (int)(test_size * X_len)\n",
    "    test_count_high = ceil(test_size * X_len)\n",
    "    \n",
    "    Xtrain_fin = X_train.shape[0]\n",
    "    ytrain_fin = y_train.shape[0]\n",
    "    Xval_fin = X_val.shape[0]\n",
    "    yval_fin = y_val.shape[0]\n",
    "    Xtest_fin = X_test.shape[0]\n",
    "    ytest_fin = y_test.shape[0]\n",
    "    \n",
    "    if not (((Xtrain_fin == train_count_low) or (Xtrain_fin == train_count_high)) and ((ytrain_fin == train_count_low) or (ytrain_fin == train_count_high))):\n",
    "        raise ValueError(f'Training set size should be approx. {train_size * X_len}, instead is: {X_train.shape[0]}')\n",
    "    if not (((Xval_fin == val_count_low) or (Xval_fin == val_count_high)) and ((yval_fin == val_count_low) or (yval_fin == val_count_high))):\n",
    "        raise ValueError(f'Validation set size should be approx. {val_size * X_len}, instead is: {X_val.shape[0]}')\n",
    "    if not (((Xtest_fin == test_count_low) or (Xtest_fin == test_count_high)) and ((ytest_fin == test_count_low) or (ytest_fin == test_count_high))):\n",
    "        raise ValueError(f'Test set size should be approx. {test_size * X_len}, instead is: {X_test.shape[0]}')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a2e7c-af05-4a1b-9c1c-1043ee61cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLpipe_Stratified_Continous_r2(X, y, preprocessor, ML_algo, param_grid, xgb=False):\n",
    "    '''\n",
    "    This function splits the data to train, validation, and test (60/20/20).\n",
    "    The R^2 is maximized in cross-validation.\n",
    "    \n",
    "    This function:\n",
    "    1. Loops through 10 different random states\n",
    "    2. Splits the data 60/20/20.\n",
    "    3. Fits a model with the predefined Preprocessor, trains the model with each hyperparameter combination in param_grid\n",
    "    4. Calculates the model's error on the test set on the model with the best hyperparameter combinations in param_grid\n",
    "    5. Returns a list of 10 test scores and 10 best models\n",
    "    '''\n",
    "    \n",
    "    # lists to be returned\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    test_Xs = []\n",
    "    test_ys = []\n",
    "\n",
    "    nr_states = 10\n",
    "    for i in range(nr_states):\n",
    "        rs = 28 * i\n",
    "        print('Random State:', rs)\n",
    "\n",
    "        # split\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = stratified_continuous_split(X, y, train_size=0.6, val_size=0.2, test_size=0.2, random_state=rs)\n",
    "\n",
    "        # preprocess\n",
    "        X_train_prep = preprocessor.fit_transform(X_train)\n",
    "        X_val_prep = preprocessor.transform(X_val)\n",
    "        X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "        # final preprocess with Standard Scaler so that I can use the coefficients of linear models as global importance metrics\n",
    "        final_scaler = StandardScaler()\n",
    "        X_train_prep = final_scaler.fit_transform(X_train_prep)\n",
    "        X_val_prep = final_scaler.transform(X_val_prep)\n",
    "        X_test_prep = final_scaler.transform(X_test_prep)\n",
    "\n",
    "        test_Xs.append(X_test_prep)\n",
    "        test_ys.append(y_test)\n",
    "\n",
    "        # train and perform cross-validation        \n",
    "        models = []\n",
    "        val_scores = []\n",
    "        for p in range(len(ParameterGrid(param_grid))):\n",
    "            params = ParameterGrid(param_grid)[p]\n",
    "            # print(' ',params) # TEMPORARY\n",
    "\n",
    "            if (xgb):\n",
    "                clf = ML_algo.fit(X_train_prep, y_train, early_stopping_rounds=50, eval_set=[(X_val_prep, y_val)], verbose=False)\n",
    "            else:\n",
    "                clf = ML_algo.fit(X_train_prep, y_train)\n",
    "            models.append(clf)\n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            val_scores.append(r2_score(y_val, y_val_pred))\n",
    "            # print(' Validation R^2:', val_scores[-1]) # TEMPORARY\n",
    "\n",
    "        # save results\n",
    "        print('    Best Model Parameters:', ParameterGrid(param_grid)[np.argmax(val_scores)])\n",
    "        print('    Validation Set R^2:', np.max(val_scores))\n",
    "        best_model_this_rs = models[np.argmax(val_scores)]\n",
    "        best_models.append(best_model_this_rs)\n",
    "        y_test_pred = best_model_this_rs.predict(X_test_prep)\n",
    "        test_score = r2_score(y_test, y_test_pred)\n",
    "        test_scores.append(test_score)\n",
    "        print('    Baseline R^2 (test set):', r2_score(y_test, pd.Series([2]*len(y_test))))\n",
    "        print('    Test Set R^2:', test_score)\n",
    "        \n",
    "    return test_scores, best_models, test_Xs, test_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf6053-8729-437e-a31f-da82869cc430",
   "metadata": {},
   "source": [
    "### Run and Cross Validate Several Models - R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd6384-b6e7-4806-86a5-b080ee36701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping track of scores\n",
    "models_r2s = pd.DataFrame(columns=['R^2', 'l1', 'l2', 'elastic net', 'random forest', 'SVR', 'XGBoost'])\n",
    "models_r2s['R^2'] = pd.Series(['mean', 'std dev'])\n",
    "models_r2s = models_r2s.set_index('R^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46190713-ea52-4ecf-b0c1-0115c8eb2c78",
   "metadata": {},
   "source": [
    "#### (1) Linear Regression with l1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c04d3-7481-4522-ba76-ba5246daad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_l1 = Lasso(random_state=random_state)\n",
    "l1_params = {\n",
    "    'lasso__alpha': np.linspace(math.exp(-2), math.exp(2), 21)\n",
    "}\n",
    "l1_test_scores_r2, l1_best_models_r2, l1_test_Xs_r2, l1_test_ys_r2 = MLpipe_Stratified_Continous_r2(X, y, preprocessor=preprocessor, ML_algo=lin_reg_l1, param_grid=l1_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab488ea-2330-417c-8078-f3b93ae69339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****Metrics with l1 Linear Regression:****')\n",
    "mean = np.mean(l1_test_scores_r2)\n",
    "std = np.std(l1_test_scores_r2)\n",
    "models_r2s['l1']['mean'] = mean\n",
    "models_r2s['l1']['std dev'] = std\n",
    "print('Mean R^2:', mean)\n",
    "print('Std. Deviation of R^2:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21468ce8-9b48-45b4-a873-d9734a3bb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/l1_r2.save', 'wb')\n",
    "best_model_index = np.argmax(l1_test_scores_r2)\n",
    "pickle.dump((l1_best_models_r2[best_model_index], l1_test_Xs_r2[best_model_index], l1_test_ys_r2[best_model_index]), file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f04993-0985-4e59-82b5-534e22c068ee",
   "metadata": {},
   "source": [
    "#### (2) Linear Regression with l2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1cba9-95ae-4b5f-8fc4-ace9e7f3a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_l2 = Ridge(random_state=random_state)\n",
    "l2_params = {\n",
    "    'ridge__alpha': np.linspace(math.exp(-2), math.exp(2), 21)\n",
    "}\n",
    "l2_test_scores_r2, l2_best_models_r2, l2_test_Xs_r2, l2_test_ys_r2 = MLpipe_Stratified_Continous_r2(X, y, preprocessor=preprocessor, ML_algo=lin_reg_l2, param_grid=l2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b0517-f464-44f4-b6a6-15273afde1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****Metrics with l2 Linear Regression:****')\n",
    "mean = np.mean(l2_test_scores_r2)\n",
    "std = np.std(l2_test_scores_r2)\n",
    "models_r2s['l2']['mean'] = mean\n",
    "models_r2s['l2']['std dev'] = std\n",
    "print('Mean R^2:', mean)\n",
    "print('Std. Deviation of R^2:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d1f60-62b2-474f-bb25-2188e0392eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/l2_r2.save', 'wb')\n",
    "best_model_index = np.argmax(l2_test_scores_r2)\n",
    "pickle.dump((l2_best_models_r2[best_model_index], l2_test_Xs_r2[best_model_index], l2_test_ys_r2[best_model_index]), file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f947269-268b-45d1-a528-3945a9c29776",
   "metadata": {},
   "source": [
    "#### (3) Linear Regression with Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b326e79-b284-42af-9e92-a50a85338fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_elastic = ElasticNet(random_state=random_state)\n",
    "elastic_params = {\n",
    "    'elasticnet__alpha': np.linspace(math.exp(-2), math.exp(2), 21),\n",
    "    'elasticnet__l1_ratio': np.linspace(0, 1, 21)\n",
    "}\n",
    "elastic_test_scores_r2, elastic_best_models_r2, elastic_test_Xs_r2, elastic_test_ys_r2 = MLpipe_Stratified_Continous_r2(X, y, preprocessor=preprocessor, ML_algo=lin_reg_elastic, param_grid=elastic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c320a1d-706a-4749-b997-e6ef527bf959",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****Metrics with Elastic Net Linear Regression:****')\n",
    "mean = np.mean(elastic_test_scores_r2)\n",
    "std = np.std(elastic_test_scores_r2)\n",
    "models_r2s['elastic net']['mean'] = mean\n",
    "models_r2s['elastic net']['std dev'] = std\n",
    "print('Mean R^2:', mean)\n",
    "print('Std. Deviation of R^2:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b908ad7-fe12-450b-a635-370f850928c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/elastic_net_r2.save', 'wb')\n",
    "best_model_index = np.argmax(elastic_test_scores_r2)\n",
    "pickle.dump((elastic_best_models_r2[best_model_index], elastic_test_Xs_r2[best_model_index], elastic_test_ys_r2[best_model_index]), file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa65b88-b23b-49df-b547-7df87b04d7f3",
   "metadata": {},
   "source": [
    "#### (4) Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806281a-b0a0-436a-bfed-f069b009f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg = RandomForestRegressor(n_jobs=-1, n_estimators=100, random_state=random_state)\n",
    "rf_params = {\n",
    "    'randomforestregressor__max_features': [1, 3, 10, 30],\n",
    "    'randomforestregressor__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "rf_test_scores_r2, rf_best_models_r2, rf_test_Xs_r2, rf_test_ys_r2 = MLpipe_Stratified_Continous_r2(X, y, preprocessor=preprocessor, ML_algo=random_forest_reg, param_grid=rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23783576-4818-4c28-902e-d5f7d7ef9f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****Metrics with Random Forest Regressor:****')\n",
    "mean = np.mean(rf_test_scores_r2)\n",
    "std = np.std(rf_test_scores_r2)\n",
    "models_r2s['random forest']['mean'] = mean\n",
    "models_r2s['random forest']['std dev'] = std\n",
    "print('Mean R^2:', mean)\n",
    "print('Std. Deviation of R^2:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021f144-6de2-4702-b5c6-9398556282a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/random_forest_regressor_r2.save', 'wb')\n",
    "best_model_index = np.argmax(rf_test_scores_r2)\n",
    "pickle.dump((rf_best_models_r2[best_model_index], rf_test_Xs_r2[best_model_index], rf_test_ys_r2[best_model_index]), file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896cc948-9cd6-4640-8f51-31635e48d27a",
   "metadata": {},
   "source": [
    "#### (5) SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48046c3-3b6d-4566-ba2b-c2e84ade06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr_params = {\n",
    "    'svr__gamma': [1e-3, 1e-1, 1e1, 1e3, 1e5],\n",
    "    'svr__C': [1e-1, 1e0, 1e1]\n",
    "}\n",
    "svr_test_scores_r2, svr_best_models_r2, svr_test_Xs_r2, svr_test_ys_r2 = MLpipe_Stratified_Continous_r2(X, y, preprocessor=preprocessor, ML_algo=svr, param_grid=svr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9e24d-bac3-4bc1-98eb-568603127fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****Metrics with SVR:****')\n",
    "mean = np.mean(svr_test_scores_r2)\n",
    "std = np.std(svr_test_scores_r2)\n",
    "models_r2s['SVR']['mean'] = mean\n",
    "models_r2s['SVR']['std dev'] = std\n",
    "print('Mean R^2:', mean)\n",
    "print('Std. Deviation of R^2:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbec3c8-e253-447e-9106-4a4a60d4052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/svr_r2.save', 'wb')\n",
    "best_model_index = np.argmax(svr_test_scores_r2)\n",
    "pickle.dump((svr_best_models_r2[best_model_index], svr_test_Xs_r2[best_model_index], svr_test_ys_r2[best_model_index]), file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f1099-c290-4c89-877f-59562024dcab",
   "metadata": {},
   "source": [
    "#### (6) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2eba0d-ab75-4a12-97c5-a36afd026613",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(seed=0, n_estimators=10000, learning_rate=0.03, colsample_bytree=0.9, subsample=0.66)\n",
    "xgb_params = {\n",
    "    'xgbregressor__reg_alpha': [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    'xgbregressor__lambda': [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    'xgbregressor__max_depth': [1, 3, 10, 30, 100]\n",
    "}\n",
    "xgb_test_scores_r2, xgb_best_models_r2, xgb_test_Xs_r2, xgb_test_ys_r2 = MLpipe_Stratified_Continous_r2(X, y, preprocessor=preprocessor, ML_algo=xgb, param_grid=xgb_params, xgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9917fd-5301-4e20-9760-000fa80afe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****Metrics with XGBoost:****')\n",
    "mean = np.mean(xgb_test_scores_r2)\n",
    "std = np.std(xgb_test_scores_r2)\n",
    "models_r2s['XGBoost']['mean'] = mean\n",
    "models_r2s['XGBoost']['std dev'] = std\n",
    "print('Mean R^2:', mean)\n",
    "print('Std. Deviation of R^2:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5d4bb-a232-4203-bec4-98dd7d2a9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/xgboost_r2.save', 'wb')\n",
    "best_model_index = np.argmax(xgb_test_scores_r2)\n",
    "pickle.dump((xgb_best_models_r2[best_model_index], xgb_test_Xs_r2[best_model_index], xgb_test_ys_r2[best_model_index]), file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13de3f-3e3b-4d8f-bf68-1194bf28bfe5",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71965896-d218-4857-815b-a237a5343d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_r2s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
