{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_regression_split(X:pd.DataFrame, y:pd.Series, train_size:float, val_size:float, test_size:float, n_bins: int, random_state:int):\n",
    "    '''\n",
    "    Performs a stratified split of inputted data (with respect to y) into a training set, validation set, and test set to specified percentages \n",
    "    of the data and performs basic error checking.\n",
    "\n",
    "    Parameters:\n",
    "    - X: a 2D pandas DataFrame, the feature matrix\n",
    "    - y: a 1D pandas Series, the target variable matrix matching X\n",
    "    - train_size: a float between 0 and 1, the percentage of X which should be training data\n",
    "    - val_size: a float between 0 and 1, the percentage of X which should be reserved for validation\n",
    "    - test_size: a float between 0 and 1, the percentage of X which should be reserved for final testing\n",
    "    - n_bins: an int, the number of bins to categorize the target variable y using (in order to perform stratified split)\n",
    "    - random_state: an int, the random state to split with\n",
    "    Note: The sum of train_size + val_size + test_size must be 1.0 (100% of X).\n",
    "\n",
    "    Returns:\n",
    "    - (X_train) a 2D pandas DataFrame, the feature matrix of training data\n",
    "    - (y_train) a 1D pandas Series, the target variable matrix for training data\n",
    "    - (X_val) a 2D pandas DataFrame, the feature matrix of validation data\n",
    "    - (y_val) a 1D pandas Series, the target variable matrix for validation data\n",
    "    - (X_test) a 2D pandas DataFrame, the feature matrix of testing data\n",
    "    - (y_test) a 1D pandas Series, the target variable matrix for testing data\n",
    "\n",
    "    Raises:\n",
    "    - ValueError for invalid input\n",
    "    '''\n",
    "    if ((train_size + val_size + test_size) != 1):\n",
    "        raise ValueError('Your train_size + val_size + test_size must add up to 1 (100%)!')\n",
    "    if (not isinstance(random_state, int)):\n",
    "        raise ValueError('Your random_state must be an int!')\n",
    "\n",
    "    bins = [1, 2, 4, 8, 17]\n",
    "    # y_binned = np.digitize(y,bins)\n",
    "    for val in bins:\n",
    "        print(val)\n",
    "\n",
    "    X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=train_size, stratify=y_binned, random_state=random_state)\n",
    "    \n",
    "    X_len = X.shape[0]\n",
    "    val_percent_of_other = (val_size * X_len)/(X_len - (train_size * X_len))\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=val_percent_of_other, stratify=y_binned, random_state=random_state)\n",
    "    \n",
    "    train_count_low = (int)(train_size * X_len)\n",
    "    train_count_high = ceil(train_size * X_len)\n",
    "    val_count_low = (int)(val_size * X_len)\n",
    "    val_count_high = ceil(val_size * X_len)\n",
    "    test_count_low = (int)(test_size * X_len)\n",
    "    test_count_high = ceil(test_size * X_len)\n",
    "    \n",
    "    Xtrain_fin = X_train.shape[0]\n",
    "    ytrain_fin = y_train.shape[0]\n",
    "    Xval_fin = X_val.shape[0]\n",
    "    yval_fin = y_val.shape[0]\n",
    "    Xtest_fin = X_test.shape[0]\n",
    "    ytest_fin = y_test.shape[0]\n",
    "    \n",
    "    if not (((Xtrain_fin == train_count_low) or (Xtrain_fin == train_count_high)) and ((ytrain_fin == train_count_low) or (ytrain_fin == train_count_high))):\n",
    "        raise ValueError(f'Training set size should be approx. {train_size * X_len}, instead is: {X_train.shape[0]}')\n",
    "    if not (((Xval_fin == val_count_low) or (Xval_fin == val_count_high)) and ((yval_fin == val_count_low) or (yval_fin == val_count_high))):\n",
    "        raise ValueError(f'Validation set size should be approx. {val_size * X_len}, instead is: {X_val.shape[0]}')\n",
    "    if not (((Xtest_fin == test_count_low) or (Xtest_fin == test_count_high)) and ((ytest_fin == test_count_low) or (ytest_fin == test_count_high))):\n",
    "        raise ValueError(f'Test set size should be approx. {test_size * X_len}, instead is: {X_test.shape[0]}')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_split(X:pd.DataFrame, y:pd.Series, train_size:float, val_size:float, test_size:float, random_state:int):\n",
    "    '''\n",
    "    Performs a split of inputted data into a training set, validation set, and test set to specified percentages of the data and\n",
    "    performs basic error checking.\n",
    "\n",
    "    Parameters:\n",
    "    - X: a 2D pandas DataFrame, the feature matrix\n",
    "    - y: a 1D pandas Series, the target variable matrix matching X\n",
    "    - train_size: a float between 0 and 1, the percentage of X which should be training data\n",
    "    - val_size: a float between 0 and 1, the percentage of X which should be reserved for validation\n",
    "    - test_size: a float between 0 and 1, the percentage of X which should be reserved for final testing\n",
    "    - random_state: an int, the random state to split with\n",
    "    Note: The sum of train_size + val_size + test_size must be 1.0 (100% of X).\n",
    "\n",
    "    Returns:\n",
    "    - (X_train) a 2D pandas DataFrame, the feature matrix of training data\n",
    "    - (y_train) a 1D pandas Series, the target variable matrix for training data\n",
    "    - (X_val) a 2D pandas DataFrame, the feature matrix of validation data\n",
    "    - (y_val) a 1D pandas Series, the target variable matrix for validation data\n",
    "    - (X_test) a 2D pandas DataFrame, the feature matrix of testing data\n",
    "    - (y_test) a 1D pandas Series, the target variable matrix for testing data\n",
    "\n",
    "    Raises:\n",
    "    - ValueError for invalid input\n",
    "    '''\n",
    "    if ((train_size + val_size + test_size) != 1):\n",
    "        raise ValueError('Your train_size + val_size + test_size must add up to 1 (100%)!')\n",
    "    if (not isinstance(random_state, int)):\n",
    "        raise ValueError('Your random_state must be an int!')\n",
    "\n",
    "    X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
    "    \n",
    "    X_len = X.shape[0]\n",
    "    val_percent_of_other = (val_size * X_len)/(X_len - (train_size * X_len))\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=val_percent_of_other, random_state=random_state)\n",
    "    \n",
    "    train_count_low = (int)(train_size * X_len)\n",
    "    train_count_high = ceil(train_size * X_len)\n",
    "    val_count_low = (int)(val_size * X_len)\n",
    "    val_count_high = ceil(val_size * X_len)\n",
    "    test_count_low = (int)(test_size * X_len)\n",
    "    test_count_high = ceil(test_size * X_len)\n",
    "    \n",
    "    Xtrain_fin = X_train.shape[0]\n",
    "    ytrain_fin = y_train.shape[0]\n",
    "    Xval_fin = X_val.shape[0]\n",
    "    yval_fin = y_val.shape[0]\n",
    "    Xtest_fin = X_test.shape[0]\n",
    "    ytest_fin = y_test.shape[0]\n",
    "    \n",
    "    if not (((Xtrain_fin == train_count_low) or (Xtrain_fin == train_count_high)) and ((ytrain_fin == train_count_low) or (ytrain_fin == train_count_high))):\n",
    "        raise ValueError(f'Training set size should be approx. {train_size * X_len}, instead is: {X_train.shape[0]}')\n",
    "    if not (((Xval_fin == val_count_low) or (Xval_fin == val_count_high)) and ((yval_fin == val_count_low) or (yval_fin == val_count_high))):\n",
    "        raise ValueError(f'Validation set size should be approx. {val_size * X_len}, instead is: {X_val.shape[0]}')\n",
    "    if not (((Xtest_fin == test_count_low) or (Xtest_fin == test_count_high)) and ((ytest_fin == test_count_low) or (ytest_fin == test_count_high))):\n",
    "        raise ValueError(f'Test set size should be approx. {test_size * X_len}, instead is: {X_test.shape[0]}')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verstack.stratified_continuous_split import scsplit\n",
    "\n",
    "X_train, X_other, y_train, y_other = scsplit(X, y, stratify=y, test_size=0.4, random_state=23)\n",
    "\n",
    "X_len = X.shape[0]\n",
    "val_percent_of_other = (0.2 * X_len)/(X_len - (0.6 * X_len))\n",
    "X_other = X_other.reset_index(drop=True)\n",
    "y_other = y_other.reset_index(drop=True)\n",
    "X_val, X_test, y_val, y_test = scsplit(X_other, y_other, stratify=y_other, test_size=(1-val_percent_of_other), random_state=23)\n",
    "\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_val,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function scsplit in module verstack.stratified_continuous_split:\n",
      "\n",
      "scsplit(*args, stratify, test_size=0.3, train_size=0.7, continuous=True, random_state=None)\n",
      "    Create stratfied splits for based on categoric or continuous column.\n",
      "    \n",
      "    For categoric target stratification raw sklearn is used, for continuous target\n",
      "    stratification binning of the target variable is performed before split.\n",
      "    \n",
      "    Args:\n",
      "        *args (pd.DataFrame/pd.Series): one dataframe to split into train, test\n",
      "            or X, y to split into X_train, X_val, y_train, y_val.\n",
      "        stratify (pd.Series): column used for stratification. Can be either a\n",
      "        column inside dataset:\n",
      "            train, test = scsplit(data, stratify = data['col'],...)\n",
      "        or a separate pd.Series object:\n",
      "            X_train, X_val, y_train, y_val = scsplit(X, y, stratify = y).\n",
      "        test_size (float): test split size. Defaults to 0.3.\n",
      "        train_size (float): train split size. Defaults to 0.7.\n",
      "        continuous (bool): continuous or categoric target variabale. Defaults to True.\n",
      "        random_state (int): random state value. Defaults to None.\n",
      "    \n",
      "    Returns:\n",
      "        if a single object is passed for stratification (E.g. 'data'):\n",
      "            return:\n",
      "                train (pd.DataFrame): train split\n",
      "                valid (pd.DataFrame): valid split\n",
      "        if two objects are passed for stratification (E.g. 'X', 'y'):\n",
      "            return:\n",
      "                X_train (pd.DataFrame): train split independent features\n",
      "                X_val (pd.DataFrame): valid split independent features\n",
      "                X_train (pd.DataFrame): train split target variable\n",
      "                X_train (pd.DataFrame): valid split target variable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from verstack.stratified_continuous_split import scsplit\n",
    "help(scsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(np.min(y), np.max(y), n+1)   # n = number of bins, the scsplit algorithm creates 1 bin for each unique value of y\n",
    "\n",
    "y_binned = np.digitize(y, bins) # converts each value in y to the index of the bin it belongs in\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=train_size, stratify=y_binned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
