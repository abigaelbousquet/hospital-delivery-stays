{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_regression_split(X:pd.DataFrame, y:pd.Series, train_size:float, val_size:float, test_size:float, n_bins: int, random_state:int):\n",
    "    '''\n",
    "    Performs a stratified split of inputted data (with respect to y) into a training set, validation set, and test set to specified percentages \n",
    "    of the data and performs basic error checking.\n",
    "\n",
    "    Parameters:\n",
    "    - X: a 2D pandas DataFrame, the feature matrix\n",
    "    - y: a 1D pandas Series, the target variable matrix matching X\n",
    "    - train_size: a float between 0 and 1, the percentage of X which should be training data\n",
    "    - val_size: a float between 0 and 1, the percentage of X which should be reserved for validation\n",
    "    - test_size: a float between 0 and 1, the percentage of X which should be reserved for final testing\n",
    "    - n_bins: an int, the number of bins to categorize the target variable y using (in order to perform stratified split)\n",
    "    - random_state: an int, the random state to split with\n",
    "    Note: The sum of train_size + val_size + test_size must be 1.0 (100% of X).\n",
    "\n",
    "    Returns:\n",
    "    - (X_train) a 2D pandas DataFrame, the feature matrix of training data\n",
    "    - (y_train) a 1D pandas Series, the target variable matrix for training data\n",
    "    - (X_val) a 2D pandas DataFrame, the feature matrix of validation data\n",
    "    - (y_val) a 1D pandas Series, the target variable matrix for validation data\n",
    "    - (X_test) a 2D pandas DataFrame, the feature matrix of testing data\n",
    "    - (y_test) a 1D pandas Series, the target variable matrix for testing data\n",
    "\n",
    "    Raises:\n",
    "    - ValueError for invalid input\n",
    "    '''\n",
    "    if ((train_size + val_size + test_size) != 1):\n",
    "        raise ValueError('Your train_size + val_size + test_size must add up to 1 (100%)!')\n",
    "    if (not isinstance(random_state, int)):\n",
    "        raise ValueError('Your random_state must be an int!')\n",
    "\n",
    "    bins = [1, 2, 4, 8, 17]\n",
    "    # y_binned = np.digitize(y,bins)\n",
    "    for val in bins:\n",
    "        print(val)\n",
    "\n",
    "    X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=train_size, stratify=y_binned, random_state=random_state)\n",
    "    \n",
    "    X_len = X.shape[0]\n",
    "    val_percent_of_other = (val_size * X_len)/(X_len - (train_size * X_len))\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=val_percent_of_other, stratify=y_binned, random_state=random_state)\n",
    "    \n",
    "    train_count_low = (int)(train_size * X_len)\n",
    "    train_count_high = ceil(train_size * X_len)\n",
    "    val_count_low = (int)(val_size * X_len)\n",
    "    val_count_high = ceil(val_size * X_len)\n",
    "    test_count_low = (int)(test_size * X_len)\n",
    "    test_count_high = ceil(test_size * X_len)\n",
    "    \n",
    "    Xtrain_fin = X_train.shape[0]\n",
    "    ytrain_fin = y_train.shape[0]\n",
    "    Xval_fin = X_val.shape[0]\n",
    "    yval_fin = y_val.shape[0]\n",
    "    Xtest_fin = X_test.shape[0]\n",
    "    ytest_fin = y_test.shape[0]\n",
    "    \n",
    "    if not (((Xtrain_fin == train_count_low) or (Xtrain_fin == train_count_high)) and ((ytrain_fin == train_count_low) or (ytrain_fin == train_count_high))):\n",
    "        raise ValueError(f'Training set size should be approx. {train_size * X_len}, instead is: {X_train.shape[0]}')\n",
    "    if not (((Xval_fin == val_count_low) or (Xval_fin == val_count_high)) and ((yval_fin == val_count_low) or (yval_fin == val_count_high))):\n",
    "        raise ValueError(f'Validation set size should be approx. {val_size * X_len}, instead is: {X_val.shape[0]}')\n",
    "    if not (((Xtest_fin == test_count_low) or (Xtest_fin == test_count_high)) and ((ytest_fin == test_count_low) or (ytest_fin == test_count_high))):\n",
    "        raise ValueError(f'Test set size should be approx. {test_size * X_len}, instead is: {X_test.shape[0]}')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_split(X:pd.DataFrame, y:pd.Series, train_size:float, val_size:float, test_size:float, random_state:int):\n",
    "    '''\n",
    "    Performs a split of inputted data into a training set, validation set, and test set to specified percentages of the data and\n",
    "    performs basic error checking.\n",
    "\n",
    "    Parameters:\n",
    "    - X: a 2D pandas DataFrame, the feature matrix\n",
    "    - y: a 1D pandas Series, the target variable matrix matching X\n",
    "    - train_size: a float between 0 and 1, the percentage of X which should be training data\n",
    "    - val_size: a float between 0 and 1, the percentage of X which should be reserved for validation\n",
    "    - test_size: a float between 0 and 1, the percentage of X which should be reserved for final testing\n",
    "    - random_state: an int, the random state to split with\n",
    "    Note: The sum of train_size + val_size + test_size must be 1.0 (100% of X).\n",
    "\n",
    "    Returns:\n",
    "    - (X_train) a 2D pandas DataFrame, the feature matrix of training data\n",
    "    - (y_train) a 1D pandas Series, the target variable matrix for training data\n",
    "    - (X_val) a 2D pandas DataFrame, the feature matrix of validation data\n",
    "    - (y_val) a 1D pandas Series, the target variable matrix for validation data\n",
    "    - (X_test) a 2D pandas DataFrame, the feature matrix of testing data\n",
    "    - (y_test) a 1D pandas Series, the target variable matrix for testing data\n",
    "\n",
    "    Raises:\n",
    "    - ValueError for invalid input\n",
    "    '''\n",
    "    if ((train_size + val_size + test_size) != 1):\n",
    "        raise ValueError('Your train_size + val_size + test_size must add up to 1 (100%)!')\n",
    "    if (not isinstance(random_state, int)):\n",
    "        raise ValueError('Your random_state must be an int!')\n",
    "\n",
    "    X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
    "    \n",
    "    X_len = X.shape[0]\n",
    "    val_percent_of_other = (val_size * X_len)/(X_len - (train_size * X_len))\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=val_percent_of_other, random_state=random_state)\n",
    "    \n",
    "    train_count_low = (int)(train_size * X_len)\n",
    "    train_count_high = ceil(train_size * X_len)\n",
    "    val_count_low = (int)(val_size * X_len)\n",
    "    val_count_high = ceil(val_size * X_len)\n",
    "    test_count_low = (int)(test_size * X_len)\n",
    "    test_count_high = ceil(test_size * X_len)\n",
    "    \n",
    "    Xtrain_fin = X_train.shape[0]\n",
    "    ytrain_fin = y_train.shape[0]\n",
    "    Xval_fin = X_val.shape[0]\n",
    "    yval_fin = y_val.shape[0]\n",
    "    Xtest_fin = X_test.shape[0]\n",
    "    ytest_fin = y_test.shape[0]\n",
    "    \n",
    "    if not (((Xtrain_fin == train_count_low) or (Xtrain_fin == train_count_high)) and ((ytrain_fin == train_count_low) or (ytrain_fin == train_count_high))):\n",
    "        raise ValueError(f'Training set size should be approx. {train_size * X_len}, instead is: {X_train.shape[0]}')\n",
    "    if not (((Xval_fin == val_count_low) or (Xval_fin == val_count_high)) and ((yval_fin == val_count_low) or (yval_fin == val_count_high))):\n",
    "        raise ValueError(f'Validation set size should be approx. {val_size * X_len}, instead is: {X_val.shape[0]}')\n",
    "    if not (((Xtest_fin == test_count_low) or (Xtest_fin == test_count_high)) and ((ytest_fin == test_count_low) or (ytest_fin == test_count_high))):\n",
    "        raise ValueError(f'Test set size should be approx. {test_size * X_len}, instead is: {X_test.shape[0]}')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verstack.stratified_continuous_split import scsplit\n",
    "\n",
    "X_train, X_other, y_train, y_other = scsplit(X, y, stratify=y, test_size=0.4, random_state=23)\n",
    "\n",
    "X_len = X.shape[0]\n",
    "val_percent_of_other = (0.2 * X_len)/(X_len - (0.6 * X_len))\n",
    "X_other = X_other.reset_index(drop=True)\n",
    "y_other = y_other.reset_index(drop=True)\n",
    "X_val, X_test, y_val, y_test = scsplit(X_other, y_other, stratify=y_other, test_size=(1-val_percent_of_other), random_state=23)\n",
    "\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_val,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(np.min(y), np.max(y), n+1)   # n = number of bins, the scsplit algorithm creates 1 bin for each unique value of y\n",
    "\n",
    "y_binned = np.digitize(y, bins) # converts each value in y to the index of the bin it belongs in\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=train_size, stratify=y_binned)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
